{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"olSEL3y4igVv"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import json"]},{"cell_type":"markdown","source":["Парсинг ссылок на все статьи с балансировкой L, C, R на allsides.com"],"metadata":{"id":"JKmLeAeol4NK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"DcHHgvczsTTX"},"outputs":[],"source":["num_pages = 173\n","counter = 0\n","for i in range (152, num_pages):\n","  url = f'https://www.allsides.com/headline-roundups?page={i}'\n","  response = requests.get(url)\n","\n","  soup = BeautifulSoup(response.content, 'html.parser')\n","\n","  articles = []\n","  news_list = soup.find_all('td', class_='views-field views-field-name')\n","  for news in news_list:\n","\n","      ref = news.find('a').get('href')\n","\n","\n","      article = {\n","          'heading': 'https://allsides.com' + ref,\n","      }\n","      articles.append(article)\n","      counter += 1\n","\n","  with open(f\"art_link/{i}page.json\", \"w\") as f:\n","    json.dump(articles, f, indent=2)\n","\n","print('Всего статей')\n","print(counter)\n"]},{"cell_type":"markdown","metadata":{"id":"edGdS2pwfXH-"},"source":["Функция для парсинга одной статьи в нужном json формате"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DliSmVJfe41M"},"outputs":[],"source":["from requests.exceptions import ChunkedEncodingError\n","import random\n","\n","def art_parc(url_art, label_art, counter, label_num):\n","  url = url_art\n","  label = label_art\n","  articles = []\n","\n","  while True:\n","      try:\n","          response = requests.get(url)\n","          response.raise_for_status()\n","          break\n","      except ChunkedEncodingError:\n","          print('ChunkedEncodingError occurred. Retrying...')\n","\n","  soup = BeautifulSoup(response.content, 'html.parser')\n","  news_left_list = soup.find_all('div', class_=f'news-item {label}')\n","  for news in news_left_list:\n","      if news.find('a', class_='news-title') is None:\n","          print('Skipping this news item.')\n","          continue\n","\n","      title = news.find('a', class_='news-title').get_text().strip()\n","\n","     # print(title)\n","\n","      text = news.find('div', class_=\"body-contents\").get_text().strip()\n","\n","     # print(text)\n","      id = ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))\n","      article = {\n","              'id': id,\n","              'title': title,\n","              'content': text,\n","              'label': label,\n","              'label_num': label_num\n","      }\n","      articles.append(article)\n","\n","  return articles\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGFYGSnJQt3D"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"_l4bX2Uo6wMJ"},"source":["Основная часть работы - парсинг статей по лейблам"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_A67hwcvcjC"},"outputs":[],"source":["def parc_diff_label(counter_to_start, label):\n","  counter = counter_to_start\n","\n","  # Регулируем интервал парсинга\n","  # Чтобы сохранять данные при потере интернет соединения\n","  # И прочих необрабатываемых на уровне кода случаев\n","\n","  for i in range (152,173):\n","    with open(f\"art_link/{i}page.json\", \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","\n","    # Создаем пустой массив для элементов\n","    elements = []\n","\n","    # Итерируемся по данным и добавляем элементы в массив\n","    for item in data:\n","        elements.append(item[\"heading\"])\n","\n","    # Выводим массив элементов\n","    print(elements)\n","    for els in elements:\n","        url = els\n","        print(url)\n","        articles = art_parc(url, label, counter)\n","        with open(f\"dataset/{counter}.json\", \"w\", encoding=\"utf-8\") as f:\n","          json.dump(articles, f, indent=2, ensure_ascii=False)\n","        counter += 1\n","        print(\"Страница номер \" + f\"{i}\" + \"\\n\")\n","        print(counter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fpla9Y33_yZM"},"outputs":[],"source":["# счётчик статей\n","counter_to_start = 24722\n","parc_diff_label(counter_to_start, 'right', 2)"]},{"cell_type":"markdown","metadata":{"id":"JUUfJ3_068Kt"},"source":["Архивировать и скачать датасет"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TLksTWu1z9Ui"},"outputs":[],"source":["!zip -r /content/dataset8.zip /content/dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":908,"status":"ok","timestamp":1695401923633,"user":{"displayName":"Alexandr dix-sept","userId":"16504811037991688664"},"user_tz":-180},"id":"esAlx1HH0BMq","outputId":"99f93d24-9de9-4395-8b55-a88e9679c849"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f392b2ab-9bc3-4cdf-b15d-60ccf42a4273\", \"dataset8.zip\", 464758)"]},"metadata":{}}],"source":["from google.colab import files\n","files.download(\"/content/dataset8.zip\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgqaYegJ6qMdFBfJEondbJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}